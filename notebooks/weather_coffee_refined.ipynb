{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f0b53f5-ef98-4a99-8bad-9df43f8519be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf, col, regexp_replace, current_timestamp\n",
    "from pyspark.sql.types import FloatType\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"schema_name\", \"\")\n",
    "schema_name = dbutils.widgets.get(\"schema_name\")\n",
    "catalog_name = 'shirlywang_sandbox'\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dce40e2b-d816-404c-b52b-b2cb9ab7dea9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coffee = spark.table(\"dnb_wave_5.sandbox.coffee_raw\")\n",
    "weather = spark.table(f\"{catalog_name}.{schema_name}.location_weather_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fb5beed-2acf-4a9f-b19b-4a8f63bc7cef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59de619f-9bc8-49be-86ae-0e004718e68f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "# Join coffee and weather on coffee Country of Origin and weather country\n",
    "joined = coffee.join(weather, \n",
    "                     (coffee[\"`Country of Origin`\"] == weather[\"Country\"]))\\\n",
    "                         .drop(\"country\", \"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9065b5b-c12c-4538-b052-b6c05227a7a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-2995129008927707>, line 9\u001b[0m\n",
       "\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col_name \u001b[38;5;129;01min\u001b[39;00m array_columns:\n",
       "\u001b[1;32m      8\u001b[0m     avg_col_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_avg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[0;32m----> 9\u001b[0m     joined \u001b[38;5;241m=\u001b[39m joined\u001b[38;5;241m.\u001b[39mwithColumn(avg_col_name, pandas_array_avg(joined[col_name]))\n",
       "\n",
       "\u001b[0;31mNameError\u001b[0m: name 'joined' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'joined' is not defined"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'joined' is not defined"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "File \u001b[0;32m<command-2995129008927707>, line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col_name \u001b[38;5;129;01min\u001b[39;00m array_columns:\n\u001b[1;32m      8\u001b[0m     avg_col_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_avg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     joined \u001b[38;5;241m=\u001b[39m joined\u001b[38;5;241m.\u001b[39mwithColumn(avg_col_name, pandas_array_avg(joined[col_name]))\n",
        "\u001b[0;31mNameError\u001b[0m: name 'joined' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "@pandas_udf(FloatType())\n",
    "def pandas_array_avg(arrays: pd.Series) -> pd.Series:\n",
    "    return arrays.apply(lambda arr: float(np.mean(arr)))\n",
    "\n",
    "array_columns = [\"temperature_2m_max\", \"temperature_2m_min\", \"daylight_duration\", \"uv_index_max\", \"rain_sum\", \"showers_sum\", \"snowfall_sum\"]  \n",
    "\n",
    "for col_name in array_columns:\n",
    "    avg_col_name = f\"{col_name}_avg\"\n",
    "    joined = joined.withColumn(avg_col_name, pandas_array_avg(joined[col_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9af73363-e82e-4ba6-8476-fea1d66eace1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_select = [\"Country of Origin\", \"Region\", \"Variety\", \"Processing Method\", \"Aroma\", \"Flavor\", \"Aftertaste\", \"Acidity\", \"Body\", \"Balance\", \"Uniformity\", \"Clean Cup\", \"Sweetness\", \"Overall\", \"Defects\", \"Total Cup Points\", \"Moisture Percentage\", \"Category One Defects\", \"Quakers\", \"Color\", \"Category Two Defects\", \"latitude\", \"longitude\", \"elevation\", \"temperature_2m_max_avg\", \"temperature_2m_min_avg\", \"daylight_duration_avg\", \"uv_index_max_avg\", \"rain_sum_avg\", \"showers_sum_avg\"]\n",
    "\n",
    "refined = joined.select(*[col(col_name).alias(col_name.lower().replace(\" \", \"_\")) for col_name in columns_to_select])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7593c22a-a824-47e5-908d-7fda54f52cd4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "refined = refined.withColumn(\"created_at\", current_timestamp())\n",
    "refined.write \\\n",
    "    .format(\"delta\")\\\n",
    "    .mode(\"ignore\")\\\n",
    "    .saveAsTable(f\"{catalog_name}.{schema_name}.coffee_weather_refined\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "weather_coffee_refined",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
